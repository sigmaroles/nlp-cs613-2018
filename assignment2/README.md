### Using Alice In Wonderland text

raw file is alice_wonderland.txt

### tokenizing and saving train/test corpus:
please see tokenize_save.py

### n-gram model with MLE, add one smoothing and Good-Turing smoothing
please see ngram_util.py


### "Drastic change" in counts after add one smoothing
This happens due to 

### Please run/alter demos.ipynb for the following:
- count of possible vs actual n grams
- generating sentences
- getting probability sentences
- plot of constant discounting (d) with good turing smoothing
- perplexity of sentences from test corpus